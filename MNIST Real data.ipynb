{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Admin/Desktop/CWD/DATA/MNIST REAL DATA/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.png\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from skimage import io\n",
    "cwd = 'C:/Users/Admin/Desktop/CWD/DATA/MNIST REAL DATA/Images/train'\n",
    "X = data['filename']\n",
    "Y = data['label']\n",
    "print(X[5])\n",
    "x = []\n",
    "for image in X:\n",
    "    x.append(os.path.join(cwd,image).replace(\"\\\\\",\"/\"))\n",
    "x = np.array(x)\n",
    "\n",
    "\n",
    "all_images = []\n",
    "for image_path in x:\n",
    "  img = io.imread(image_path , as_grey=True)\n",
    "  img = img.reshape(img.shape[0]*img.shape[1],)\n",
    "  all_images.append(img)\n",
    "x_train = np.array(all_images)\n",
    "y_train = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
      "(49000, 784)\n",
      "(49000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train = y_train.reshape(len(y_train), 1)\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "print(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_image_size = x_train[1].shape[0]\n",
    "no_of_classes = 10\n",
    "n_h1 = 500\n",
    "n_h2 = 450\n",
    "n_h3 = 212\n",
    "n_out = no_of_classes\n",
    "x_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_train, y_train, test_size = 0.2)\n",
    "type(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', shape = [None, flat_image_size])\n",
    "y = tf.placeholder('float', shape = [None, no_of_classes])\n",
    "\n",
    "def neural_nets(data):\n",
    "    hidden_layer_1 = {'weights': tf.Variable(tf.random_normal([flat_image_size, n_h1])),\n",
    "                      'bias': tf.Variable(tf.random_normal([n_h1]))}\n",
    "    \n",
    "    hidden_layer_2 = {'weights': tf.Variable(tf.random_normal([n_h1, n_h2])),\n",
    "                      'bias': tf.Variable(tf.random_normal([n_h2]))}\n",
    "    \n",
    "    hidden_layer_3 = {'weights': tf.Variable(tf.random_normal([n_h2, n_h3])),\n",
    "                      'bias': tf.Variable(tf.random_normal([n_h3]))}\n",
    "    \n",
    "    output = {'weights': tf.Variable(tf.random_normal([n_h3, n_out])),\n",
    "              'bias': tf.Variable(tf.random_normal([n_out]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(x,hidden_layer_1['weights']), hidden_layer_1['bias'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_layer_2['weights']), hidden_layer_2['bias'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2,hidden_layer_3['weights']), hidden_layer_3['bias'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.add(tf.matmul(l3,output['weights']), output['bias'])\n",
    "    output = tf.nn.relu(output)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "#     assert inputs.shape[0] == targets.shape[0]\n",
    "#     if shuffle:\n",
    "#         indices = np.arange(inputs.shape[0])\n",
    "#         np.random.shuffle(indices)\n",
    "#     for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "#         if shuffle:\n",
    "#             excerpt = indices[start_idx:start_idx + batchsize]\n",
    "#         else:\n",
    "#             excerpt = slice(start_idx, start_idx + batchsize)\n",
    "#         yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "        \n",
    "# for epoch in range(no_epoch):\n",
    "#     epoch_loss = 0\n",
    "#     for batch in iterate_minibatches(X, Y, batch_size, shuffle=True):\n",
    "#         x_batch, y_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------EPOCH: 0 ------------------\n",
      "Epoch 0 out of  300 Epochs Loss:  29935.0683594\n",
      "Accuracy on train-set: 13.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  56237.3125\n",
      "Accuracy on train-set: 13.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  80682.5878906\n",
      "Accuracy on train-set: 14.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  101168.080078\n",
      "Accuracy on train-set: 14.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  122283.0\n",
      "Accuracy on train-set: 15.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  140181.636719\n",
      "Accuracy on train-set: 15.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  155858.787109\n",
      "Accuracy on train-set: 16.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  172089.197266\n",
      "Accuracy on train-set: 17.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  186111.709961\n",
      "Accuracy on train-set: 18.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  198246.387695\n",
      "Accuracy on train-set: 19.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  210294.525391\n",
      "Accuracy on train-set: 21.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  221905.388672\n",
      "Accuracy on train-set: 22.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  232154.137695\n",
      "Accuracy on train-set: 23.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  242848.902344\n",
      "Accuracy on train-set: 24.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  251154.853516\n",
      "Accuracy on train-set: 25.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  261622.120117\n",
      "Accuracy on train-set: 26.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  272673.467773\n",
      "Accuracy on train-set: 27.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  282460.821289\n",
      "Accuracy on train-set: 28.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  289890.842773\n",
      "Accuracy on train-set: 29.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  296289.465332\n",
      "Accuracy on train-set: 30.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  303506.040527\n",
      "Accuracy on train-set: 31.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  309075.95752\n",
      "Accuracy on train-set: 31.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  313901.181152\n",
      "Accuracy on train-set: 32.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  318322.045898\n",
      "Accuracy on train-set: 32.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  322096.85083\n",
      "Accuracy on train-set: 32.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  325253.449219\n",
      "Accuracy on train-set: 32.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  327645.973633\n",
      "Accuracy on train-set: 31.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  329917.227783\n",
      "Accuracy on train-set: 31.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  331493.336182\n",
      "Accuracy on train-set: 30.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  333012.734741\n",
      "Accuracy on train-set: 29.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  334384.036987\n",
      "Accuracy on train-set: 28.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  335276.445557\n",
      "Accuracy on train-set: 27.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  336172.94104\n",
      "Accuracy on train-set: 26.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  336777.130493\n",
      "Accuracy on train-set: 25.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  337761.34198\n",
      "Accuracy on train-set: 24.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  338250.875977\n",
      "Accuracy on train-set: 23.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  338730.55542\n",
      "Accuracy on train-set: 22.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  339064.783661\n",
      "Accuracy on train-set: 21.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  339527.16037\n",
      "Accuracy on train-set: 20.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  339636.396767\n",
      "Accuracy on train-set: 19.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  339681.30468\n",
      "Accuracy on train-set: 18.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  339803.113892\n",
      "Accuracy on train-set: 18.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340051.186111\n",
      "Accuracy on train-set: 17.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  340164.833961\n",
      "Accuracy on train-set: 17.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  340236.700935\n",
      "Accuracy on train-set: 16.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  340337.468719\n",
      "Accuracy on train-set: 16.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  340430.565338\n",
      "Accuracy on train-set: 15.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  340564.776459\n",
      "Accuracy on train-set: 15.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340581.092802\n",
      "Accuracy on train-set: 14.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  340637.879412\n",
      "Accuracy on train-set: 14.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  340639.905687\n",
      "Accuracy on train-set: 14.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340642.185246\n",
      "Accuracy on train-set: 14.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  340644.44178\n",
      "Accuracy on train-set: 13.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  340646.514107\n",
      "Accuracy on train-set: 13.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  340648.770641\n",
      "Accuracy on train-set: 13.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  340677.667576\n",
      "Accuracy on train-set: 13.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  340679.947135\n",
      "Accuracy on train-set: 13.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340682.08854\n",
      "Accuracy on train-set: 13.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340684.299022\n",
      "Accuracy on train-set: 13.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  340737.6435\n",
      "Accuracy on train-set: 13.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  340743.604177\n",
      "Accuracy on train-set: 12.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  340745.86071\n",
      "Accuracy on train-set: 12.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  340748.071193\n",
      "Accuracy on train-set: 12.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  340774.223843\n",
      "Accuracy on train-set: 12.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  340776.503403\n",
      "Accuracy on train-set: 12.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  340778.759937\n",
      "Accuracy on train-set: 12.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  340815.220882\n",
      "Accuracy on train-set: 12.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  340832.3036\n",
      "Accuracy on train-set: 12.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  340834.537108\n",
      "Accuracy on train-set: 12.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  340836.839693\n",
      "Accuracy on train-set: 12.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  340878.250631\n",
      "Accuracy on train-set: 12.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  340880.392036\n",
      "Accuracy on train-set: 12.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340893.412202\n",
      "Accuracy on train-set: 12.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340895.622684\n",
      "Accuracy on train-set: 12.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  340923.118206\n",
      "Accuracy on train-set: 12.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340925.351714\n",
      "Accuracy on train-set: 12.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340927.631274\n",
      "Accuracy on train-set: 12.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340929.795704\n",
      "Accuracy on train-set: 12.2%\n",
      "Epoch 0 out of  300 Epochs Loss:  340959.85129\n",
      "Accuracy on train-set: 12.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  341030.486978\n",
      "Accuracy on train-set: 12.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  341032.743512\n",
      "Accuracy on train-set: 12.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  341073.807317\n",
      "Accuracy on train-set: 12.1%\n",
      "Epoch 0 out of  300 Epochs Loss:  341076.017799\n",
      "Accuracy on train-set: 12.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  341148.410659\n",
      "Accuracy on train-set: 12.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  341150.690219\n",
      "Accuracy on train-set: 12.0%\n",
      "Epoch 0 out of  300 Epochs Loss:  341152.946753\n",
      "Accuracy on train-set: 11.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  341155.249338\n",
      "Accuracy on train-set: 11.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  341174.222139\n",
      "Accuracy on train-set: 11.9%\n",
      "Epoch 0 out of  300 Epochs Loss:  341185.520897\n",
      "Accuracy on train-set: 11.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  341249.381428\n",
      "Accuracy on train-set: 11.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  341259.093758\n",
      "Accuracy on train-set: 11.8%\n",
      "Epoch 0 out of  300 Epochs Loss:  341261.373317\n",
      "Accuracy on train-set: 11.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  341263.652877\n",
      "Accuracy on train-set: 11.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  341265.955462\n",
      "Accuracy on train-set: 11.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  341420.828616\n",
      "Accuracy on train-set: 11.7%\n",
      "Epoch 0 out of  300 Epochs Loss:  341423.108176\n",
      "Accuracy on train-set: 11.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  341425.364709\n",
      "Accuracy on train-set: 11.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  341427.667295\n",
      "Accuracy on train-set: 11.6%\n",
      "Epoch 0 out of  300 Epochs Loss:  341456.593583\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341458.873143\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341461.175728\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341463.478314\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341465.688796\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341467.94533\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341482.780263\n",
      "Accuracy on train-set: 11.5%\n",
      "Epoch 0 out of  300 Epochs Loss:  341611.92928\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341614.116736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341616.396296\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341618.65283\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341620.909364\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341623.188923\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341625.445457\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341627.725017\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341630.004576\n",
      "Accuracy on train-set: 11.4%\n",
      "Epoch 0 out of  300 Epochs Loss:  341632.238085\n",
      "Accuracy on train-set: 11.3%\n",
      "Epoch 0 out of  300 Epochs Loss:  341654.81677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5400438c9c78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy on test-set: {0:.1%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mneural_nets_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-5400438c9c78>\u001b[0m in \u001b[0;36mneural_nets_train\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 feed_dict_train = {x: x_train1,\n\u001b[0;32m     36\u001b[0m                                    y: y_train1}\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy on train-set: {0:.1%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def neural_nets_train(data):\n",
    "    prediction = neural_nets(data)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    length_of_input_array = len(x_train)\n",
    "    no_epoch = 300\n",
    "    batch_size = 100\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(no_epoch):\n",
    "            epoch_loss = 0\n",
    "            print('------------------EPOCH:', epoch,'------------------')\n",
    "            for j in range(0, length_of_input_array, batch_size):\n",
    "                batch_train_X = x_train[j:j+batch_size]\n",
    "                batch_train_y = y_train[j:j+batch_size]     \n",
    "\n",
    "       \n",
    "                o,c = sess.run([optimizer, cost], feed_dict = {x:batch_train_X, y:batch_train_y})\n",
    "                epoch_loss +=c\n",
    "                print('Epoch',epoch,'out of ',no_epoch,'Epochs','Loss: ',epoch_loss)\n",
    "            \n",
    "                correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "                \n",
    "                feed_dict_train = {x: x_train1,\n",
    "                                   y: y_train1}\n",
    "                acc = sess.run(accuracy, feed_dict = feed_dict_train)\n",
    "                print(\"Accuracy on train-set: {0:.1%}\".format(acc))\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        feed_dict_test= {x: x_test1,\n",
    "                         y: y_test1}\n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict = feed_dict_test)\n",
    "        print(\"Accuracy on test-set: {0:.1%}\".format(acc))\n",
    "neural_nets_train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
